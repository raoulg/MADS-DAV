{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the parquetfile we saved in notebook 1. You will need to change the filename in the config file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "configfile = Path(\"../config.toml\").resolve()\n",
    "with configfile.open(\"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"..\").resolve()\n",
    "processed = root / Path(config[\"processed\"])\n",
    "datafile = processed / config[\"current\"]\n",
    "if not datafile.exists():\n",
    "    logger.warning(\n",
    "        f\"{datafile} does not exist. First run src/preprocess.py, and check the timestamp!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how datatypes have been preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(datafile)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the amount of messages, per author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = (\n",
    "    df[[\"author\", \"message\"]]\n",
    "    .groupby(\"author\")\n",
    "    .count()\n",
    "    .sort_values(\"message\", ascending=False)\n",
    ")\n",
    "\n",
    "k = 15\n",
    "topk = p1[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_authors = list(topk.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_topk\"] = df[\"author\"].apply(lambda x: x in topk_authors)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(y=p1.index[:k], x=\"message\", data=topk)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Sending the most messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe tweak the colors a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [0 if x < 1000 else 1 for x in topk.message]\n",
    "custom_palette = {0: \"grey\", 1: \"red\"}\n",
    "sns.barplot(\n",
    "    y=p1.index[:k],\n",
    "    x=\"message\",\n",
    "    hue=colors,\n",
    "    data=topk,\n",
    "    palette=custom_palette,\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Sending the most messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average message length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"message_length\"] = df[\"message\"].str.len()\n",
    "p1 = (\n",
    "    df[[\"author\", \"message_length\"]]\n",
    "    .groupby(\"author\")\n",
    "    .mean()\n",
    "    .sort_values(\"message_length\", ascending=False)\n",
    ")\n",
    "k = 15\n",
    "topk = p1[:k]\n",
    "sns.barplot(y=p1.index[:k], x=\"message_length\", data=topk)\n",
    "plt.xlabel(\"Average message length\")\n",
    "plt.title(\"Sending the longest messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple regex to look for links in the messages and add that as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_link = r\"http\"\n",
    "df[\"has_link\"] = df[\"message\"].str.contains(has_link)\n",
    "if df['has_link'].sum() > 0:\n",
    "    p1 = (\n",
    "        df[[\"author\", \"has_link\"]]\n",
    "        .groupby(\"author\")\n",
    "        .mean()\n",
    "        .sort_values(\"has_link\", ascending=False)\n",
    "    )\n",
    "\n",
    "    k = 15\n",
    "    topk = p1[:k]\n",
    "    sns.barplot(y=p1.index[:k], x=\"has_link\", data=topk)\n",
    "    plt.xlabel(\"Fraction of messages with a link\")\n",
    "    plt.title(\"Most links by...\")\n",
    "else:\n",
    "    logger.info(\"No links found in the messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the emojis per user (can you change between sum and mean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (\n",
    "    df[[\"author\", \"has_emoji\"]]\n",
    "    .groupby(\"author\")\n",
    "    .agg([\"sum\", \"mean\"])\n",
    "    .sort_values((\"has_emoji\", \"sum\"), ascending=False)\n",
    ")\n",
    "\n",
    "p2.columns = p2.columns.droplevel(0)\n",
    "topk = p2[:k]\n",
    "sns.barplot(y=p2.index[:k], x=\"mean\", data=topk)\n",
    "plt.xlabel(\"Average number of messages with an emoji\")\n",
    "plt.title(\"Are emoji's non-verbal?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a cateory, based on the time when authors send a message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the time ranges\n",
    "time_ranges = [\"00:00\", \"06:00\", \"08:00\", \"17:30\", \"22:00\", \"23:59\"]\n",
    "# Define the category labels\n",
    "categories = [\"night\", \"morning\", \"worktimes\", \"evening\", \"late\"]\n",
    "# Categorize the timestamp column\n",
    "df[\"timestamp_category\"] = pd.cut(\n",
    "    df[\"timestamp\"].dt.time.astype(str),\n",
    "    bins=time_ranges,\n",
    "    labels=categories,\n",
    "    right=False,\n",
    ")\n",
    "# Display the updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can group and count the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by 'author' and 'timestamp_category', and count the occurrences\n",
    "p3 = df.groupby([\"author\", \"timestamp_category\"]).size().unstack()\n",
    "\n",
    "# Calculate the fraction of each category for every author\n",
    "p3_frac = p3.div(p3.sum(axis=1), axis=0)\n",
    "p3_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use plotly the create a stacked bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = p3_frac.reset_index().melt(id_vars=\"author\")\n",
    "p4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_filtered = p4[p4[\"author\"].isin(topk_authors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(\n",
    "    p4_filtered, y=\"author\", x=\"value\", color=\"timestamp_category\", barmode=\"stack\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the minimum and maximum time of the messages for every author, and convert that to a decimal fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df[\"timestamp\"].dt.time\n",
    "summary_df = df.groupby(\"author\")[\"hour\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "\n",
    "def convert_to_decimal_hours(timestamp):\n",
    "    dec_hour = timestamp.hour + timestamp.minute / 60 + timestamp.second / 3600\n",
    "    return dec_hour\n",
    "\n",
    "\n",
    "summary_df[\"min_x_values\"] = summary_df[\"min\"].apply(convert_to_decimal_hours)\n",
    "summary_df[\"max_x_values\"] = summary_df[\"max\"].apply(convert_to_decimal_hours)\n",
    "\n",
    "# Drop the original 'min' and 'max' columns as they are no longer needed\n",
    "summary_df = summary_df.drop([\"min\", \"max\"], axis=1)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can create a nice barbell chart. Try to add colors for your own chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create scatter plots\n",
    "sns.scatterplot(data=summary_df, x=\"min_x_values\", y=\"author\", color=\"grey\")\n",
    "sns.scatterplot(data=summary_df, x=\"max_x_values\", y=\"author\", color=\"grey\")\n",
    "\n",
    "# Add lines\n",
    "for index, row in summary_df.iterrows():\n",
    "    plt.plot(\n",
    "        [row[\"min_x_values\"], row[\"max_x_values\"]],\n",
    "        [row[\"author\"], row[\"author\"]],\n",
    "        color=\"grey\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Adjust the font size of the y-axis labels if needed\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach for comparing is to create a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day_of_week\"] = df[\"timestamp\"].dt.dayofweek\n",
    "author_day_counts = df.groupby([\"author\", \"day_of_week\"]).size().unstack(fill_value=0)\n",
    "author_day_percentages = author_day_counts.div(author_day_counts.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "filtered = author_day_percentages.loc[topk_authors]\n",
    "sns.heatmap(filtered, annot=True, fmt=\".2f\", linewidths=0.5, cmap=\"vlag\")\n",
    "plt.xticks(\n",
    "    ticks=range(7),\n",
    "    labels=[\n",
    "        \"Monday\",\n",
    "        \"Tuesday\",\n",
    "        \"Wednesday\",\n",
    "        \"Thursday\",\n",
    "        \"Friday\",\n",
    "        \"Saturday\",\n",
    "        \"Sunday\",\n",
    "    ],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.title(\"Heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the new features we added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(datafile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
